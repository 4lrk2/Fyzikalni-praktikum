{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from uncertainties import ufloat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_raw\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_vids\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m300\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m300oprava.mpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Open the video file\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mVideoCapture(video_path)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Check if the video file opened successfully\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# Path to the video file\n",
    "video_path = r'_raw\\_vids\\300\\300oprava.mpg'\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video file opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "# Initialize variables to store the sum of frames and the frame count\n",
    "frame_sum = None\n",
    "frame_count = 0\n",
    "\n",
    "# Get the total number of frames in the video\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Initialize the progress bar\n",
    "progress_bar = tqdm(total=total_frames, desc=\"Processing frames\")\n",
    "\n",
    "# Loop through the video frames\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to float32 for accurate summation\n",
    "    frame = frame.astype(np.float32)\n",
    "\n",
    "    # Initialize frame_sum with the first frame\n",
    "    if frame_sum is None:\n",
    "        frame_sum = np.zeros_like(frame)\n",
    "\n",
    "    # Accumulate the sum of frames\n",
    "    frame_sum += frame\n",
    "    frame_count += 1\n",
    "\n",
    "    # Update the progress bar\n",
    "    progress_bar.update(1)\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()\n",
    "\n",
    "# Calculate the average frame\n",
    "if frame_count > 0:\n",
    "    print (\"Averaging frames...\")\n",
    "    average_frame = frame_sum / frame_count\n",
    "\n",
    "    # Convert the average frame back to uint8\n",
    "    print (\"Converting to uint8...\")\n",
    "    average_frame = average_frame.astype(np.uint8)\n",
    "\n",
    "    # Release the video capture object\n",
    "    print (\"Releasing video capture object...\")\n",
    "    cap.release()\n",
    "\n",
    "    # Display the average frame\n",
    "    print (\"Displaying average frame\")\n",
    "    cv2.imshow('Average Frame', average_frame)\n",
    "\n",
    "    # Save the average frame as an image\n",
    "    cv2.imwrite('average_frame.png', average_frame)\n",
    "else:\n",
    "    print(\"Error: No frames read from the video file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the first image to get properties\n",
    "video_path = r'_raw\\_vids\\300\\300oprava.mpg'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "# Get the width and height of the video\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "current_frame = 0\n",
    "\n",
    "# Read the first frame from the video\n",
    "ret, prev_frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Error: Could not read the first frame from the video.\")\n",
    "    exit()\n",
    "\n",
    "tracking_data_path = 'test0.csv'  # Replace with your desired CSV file path\n",
    "\n",
    "# Define the codec and create VideoWriter object to save the processed video\n",
    "output_path = 'test0.mp4'  # Replace with your output video file path\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4 file\n",
    "fps = 30  # Frames per second\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Parameters for ShiTomasi corner detection\n",
    "feature_params = dict(maxCorners=10000, qualityLevel=0.5, minDistance=30, blockSize=20)\n",
    "\n",
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=3, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.03))\n",
    "\n",
    "# Take the first image and find corners in it\n",
    "# Check if the first frame was read successfully\n",
    "if prev_frame is None:\n",
    "    print(\"Error: First frame is empty.\")\n",
    "    exit()\n",
    "\n",
    "# Convert the first frame to grayscale\n",
    "old_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Initialize the mask to zeros\n",
    "# Ensure mask is of type CV_8UC1 and has the same size as old_gray\n",
    "maskexc = np.ones_like(old_gray, dtype=np.uint8) * 255\n",
    "\n",
    "# Set the mask to exclude a rectangle from 0-200px in both x and y directions (top-left corner which had a lot of unwanted artifacts)\n",
    "#maskexc[0:307, 0:367] = 0\n",
    "\n",
    "# Verify the mask\n",
    "#assert maskexc.dtype == np.uint8, \"Mask must be of type uint8\"\n",
    "#assert maskexc.shape == old_gray.shape, \"Mask must have the same size as the input image\"\n",
    "\n",
    "# Detect initial points to track\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask=maskexc, **feature_params)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_gray)\n",
    "\n",
    "# Initialize a dictionary to store tracking data\n",
    "tracking_data = {}\n",
    "\n",
    "# Initialize a dictionary to store total movement of each point\n",
    "total_movement = {i: 0 for i in range(len(p0))}\n",
    "\n",
    "# Initialize a dictionary to store the lifespan of each point\n",
    "lifespan = {i: 0 for i in range(len(p0))}\n",
    "\n",
    "# Initialize a list to store the original indexes of the points\n",
    "original_indexes = list(range(len(p0)))\n",
    "\n",
    "# Threshold for filtering stationary points\n",
    "movement_threshold = 5.0  # Adjust this value as needed\n",
    "min_distance_from_existing = 50  # Adjust this value as needed\n",
    "\n",
    "# Minimum lifespan for points to be kept\n",
    "min_lifespan = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   0%|          | 0/3771 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:665: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'cv::arithm_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m     frame_tracking_data[\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mi] \u001b[38;5;241m=\u001b[39m a  \u001b[38;5;66;03m# Set x coordinate\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     frame_tracking_data[\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m b  \u001b[38;5;66;03m# Set y coordinate\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Write the processed frame to the output video\u001b[39;00m\n\u001b[0;32m     63\u001b[0m out\u001b[38;5;241m.\u001b[39mwrite(img)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:665: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'cv::arithm_op'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "progress_bar = tqdm(total=total_frames, desc=\"Processing frames\")\n",
    "\n",
    "\n",
    "# Loop through the image sequence\n",
    "frame_idx = 0\n",
    "while current_frame < total_frames:\n",
    "    # Read the next frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Update the progress bar\n",
    "    progress_bar.update(1)\n",
    "    # Calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    if p1 is not None and st is not None and err is not None:\n",
    "        good_new = p1[st == 1]\n",
    "        good_old = p0[st == 1]\n",
    "        good_indexes = [original_indexes[i] for i in range(len(st)) if st[i] == 1]\n",
    "\n",
    "        # Calculate the distance moved by each point\n",
    "        distances = np.linalg.norm(good_new - good_old, axis=1)\n",
    "\n",
    "        # Update the total movement and lifespan for each point\n",
    "        for i, dist in zip(good_indexes, distances):\n",
    "            total_movement[i] += dist\n",
    "            lifespan[i] += 1\n",
    "\n",
    "        # Draw the tracks and save tracking data\n",
    "        max_index = max(good_indexes) if good_indexes else 0\n",
    "        frame_tracking_data = [None] * (2 * (max_index + 1))  # Initialize with None\n",
    "        for i, (new, old) in zip(good_indexes, zip(good_new, good_old)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            frame = cv2.circle(frame, (int(a), int(b)), 7, (0, 0, 200), -1)\n",
    "    else:\n",
    "        print(f\"Optical flow calculation failed at frame {frame_idx}\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Update the total movement and lifespan for each point\n",
    "    for i, dist in zip(good_indexes, distances):\n",
    "        total_movement[i] += dist\n",
    "        lifespan[i] += 1\n",
    "\n",
    "    # Draw the tracks and save tracking data\n",
    "    max_index = max(good_indexes) if good_indexes else 0\n",
    "    frame_tracking_data = [None] * (2 * (max_index + 1))  # Initialize with None\n",
    "    \n",
    "    for i, (new, old) in zip(good_indexes, zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 4, (0, 0, 200), -1)\n",
    "        frame = cv2.putText(frame, str(i), (int(a)+4, int(b)+4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (10, 10, 10), 1, cv2.LINE_AA)\n",
    "        frame_tracking_data[2*i] = a  # Set x coordinate\n",
    "        frame_tracking_data[2*i+1] = b  # Set y coordinate\n",
    "\n",
    "    img = cv2.add(frame, mask)\n",
    "\n",
    "    # Write the processed frame to the output video\n",
    "    out.write(img)\n",
    "\n",
    "    # Store frame tracking data in the dictionary\n",
    "    tracking_data[frame_idx] = frame_tracking_data\n",
    "\n",
    "    # Update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = np.array(good_new).reshape(-1, 1, 2)\n",
    "    original_indexes = good_indexes\n",
    "\n",
    "    # Detect new points to track every 30 frames\n",
    "    if frame_idx % 30 == 0:\n",
    "        new_points = cv2.goodFeaturesToTrack(frame_gray, mask=maskexc, **feature_params)\n",
    "        if new_points is not None:\n",
    "            # Filter new points to ensure they are not close to existing points\n",
    "            filtered_new_points = []\n",
    "            for new_point in new_points:\n",
    "                new_x, new_y = new_point.ravel()\n",
    "                too_close = False\n",
    "                for existing_point in p0:\n",
    "                    existing_x, existing_y = existing_point.ravel()\n",
    "                    distance = np.sqrt((new_x - existing_x)**2 + (new_y - existing_y)**2)\n",
    "                    if distance < min_distance_from_existing:\n",
    "                        too_close = True\n",
    "                        break\n",
    "                if not too_close:\n",
    "                    filtered_new_points.append(new_point)\n",
    "            \n",
    "            if filtered_new_points:\n",
    "                filtered_new_points = np.array(filtered_new_points).reshape(-1, 1, 2)\n",
    "                p0 = np.vstack((p0, filtered_new_points))\n",
    "                for i in range(len(filtered_new_points)):\n",
    "                    total_movement[len(total_movement)] = 0\n",
    "                    lifespan[len(lifespan)] = 0\n",
    "                    original_indexes.append(len(original_indexes))\n",
    "    cv2.imshow('frame', img)\n",
    "    current_frame += 1\n",
    "    frame_idx += 1\n",
    "\n",
    "    \n",
    "        \n",
    "progress_bar.close()\n",
    "\n",
    "# Release the video writer object\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Filter out points based on total movement and lifespan\n",
    "moving_points_indices = [i for i, total_dist in total_movement.items() if total_dist > movement_threshold and lifespan[i] >= min_lifespan]\n",
    "\n",
    "# Filter tracking data to include only moving points\n",
    "filtered_tracking_data = {}\n",
    "for frame_idx, frame_data in tracking_data.items():\n",
    "    filtered_frame_data = []\n",
    "    for i in moving_points_indices:\n",
    "        if 2*i+1 < len(frame_data) and frame_data[2*i] is not None and frame_data[2*i+1] is not None:\n",
    "            filtered_frame_data.extend([frame_data[2*i], frame_data[2*i+1]])\n",
    "        else:\n",
    "            filtered_frame_data.extend([None, None])\n",
    "    filtered_tracking_data[frame_idx] = filtered_frame_data\n",
    "\n",
    "# Convert filtered tracking data dictionary to DataFrame\n",
    "df_tracking = pd.DataFrame.from_dict(filtered_tracking_data, orient='index')\n",
    "\n",
    "# Generate column names\n",
    "num_points = df_tracking.shape[1] // 2\n",
    "column_names = []\n",
    "for i in range(num_points):\n",
    "    column_names.append(f'Point_{i}_x')\n",
    "    column_names.append(f'Point_{i}_y')\n",
    "\n",
    "# Assign column names to DataFrame\n",
    "df_tracking.columns = column_names\n",
    "\n",
    "# Export tracking data to CSV\n",
    "df_tracking.to_csv(tracking_data_path, index_label='Frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['ID', 'r', 'ratio10/5', 'ratio15/10'])\n",
    "file_path = 'Metoda3.csv'\n",
    "\n",
    "# Suppress pandas PerformanceWarnings for better readability\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Constants\n",
    "px = ufloat (53.3e-9,0.17e-9)\n",
    "T = 295.05\n",
    "R = 8.314\n",
    "eta = 0.9589e-3\n",
    "Na = 6.02214076e23\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "len0 = len(df.columns)\n",
    "\n",
    "\n",
    "# Create new columns by subtracting the next row cell from the previous row cell for each column / Delta x/y\n",
    "for col in df.columns:\n",
    "    df[f'Delta_{col}'] = df[col].diff(-1)\n",
    "    # Remove physically improbable outliers \n",
    "    df.loc[(df[f'Delta_{col}'] < -100) | (df[f'Delta_{col}'] > 100), f'Delta_{col}'] = np.nan\n",
    "\n",
    "len1 = len(df.columns)\n",
    "\n",
    "progresslen =( len1 - len0)/2\n",
    "progress_bar = tqdm(total=progresslen, position=0, leave=False)\n",
    "# Subtract every two columns\n",
    "for i in range(len0, len(df.columns), 2):\n",
    "    col1 = df.columns[i+1]\n",
    "    col2 = df.columns[i + 2]\n",
    "    # Calculate the RMS values for each pair of columns - this is RMS of the distance travelled in 150, 300 and 450 frames\n",
    "    df[f'RMS150_{col1}/{col2}'] = (df[col1].rolling(window=150).sum()**2 + df[col2].rolling(window=150).sum()**2)\n",
    "    df[f'RMS300_{col1}/{col2}'] = (df[col1].rolling(window=300).sum()**2 + df[col2].rolling(window=300).sum()**2)\n",
    "    df[f'RMS450_{col1}/{col2}'] = (df[col1].rolling(window=450).sum()**2 + df[col2].rolling(window=450).sum()**2)\n",
    "\n",
    "    #Drop the NaN values, calculate the mean and standard error of the mean for the RMS values for 150,300 and 450 respectively. Store as ufloat to be able to work with uncertainties\n",
    "    if df[f'RMS150_{col1}/{col2}'].dropna().empty:\n",
    "        df[f'FNM150{col1}/{col2}'] = np.nan\n",
    "    else:\n",
    "            mean_val = df[f'RMS150_{col1}/{col2}'].dropna().mean()\n",
    "            std_err = df[f'RMS150_{col1}/{col2}'].dropna().sem()\n",
    "            df[f'FNM150{col1}/{col2}'] = ufloat(mean_val, std_err)      \n",
    "\n",
    "    if df[f'RMS300_{col1}/{col2}'].dropna().empty:\n",
    "        df[f'FNM300{col1}/{col2}'] = np.nan\n",
    "    else:\n",
    "        mean_val = df[f'RMS300_{col1}/{col2}'].dropna().mean()\n",
    "        std_err = df[f'RMS300_{col1}/{col2}'].dropna().sem()\n",
    "        df[f'FNM300{col1}/{col2}'] = ufloat(mean_val, std_err)\n",
    "\n",
    "    if df[f'RMS450_{col1}/{col2}'].dropna().empty:\n",
    "        df[f'FNM450{col1}/{col2}'] = np.nan\n",
    "    else:\n",
    "        mean_val = df[f'RMS450_{col1}/{col2}'].dropna().mean()\n",
    "        std_err = df[f'RMS450_{col1}/{col2}'].dropna().sem()\n",
    "        df[f'FNM450{col1}/{col2}'] = ufloat(mean_val, std_err)\n",
    "        \n",
    "    df[f'ratio10/5{col1}/{col2}'] = df[f'FNM300{col1}/{col2}'] / df[f'FNM150{col1}/{col2}']\n",
    "    df[f'ratio15/10{col1}/{col2}'] = df[f'FNM450{col1}/{col2}'] / df[f'FNM150{col1}/{col2}']\n",
    "\n",
    "    # Check if the ratios are within the acceptable range and calculate the radius. Convert pixel values to meters print in nm for better readability\n",
    "    if 1.85 <= df[f'ratio10/5{col1}/{col2}'].iloc[0] <= 2.15:\n",
    "        if 2.75 <= df[f'ratio15/10{col1}/{col2}'].iloc[0] <= 3.25:\n",
    "            df[f'r1-{col1}/{col2}'] = (((2*R*T*5)/(3*np.pi*eta*Na*df[f'FNM150{col1}/{col2}'].iloc[0]*(px**2))))\n",
    "            df[f'r2-{col1}/{col2}'] = (((2*R*T*10)/(3*np.pi*eta*Na*df[f'FNM300{col1}/{col2}'].iloc[0]*(px**2))))\n",
    "            df[f'r3-{col1}/{col2}'] = (((2*R*T*15)/(3*np.pi*eta*Na*df[f'FNM450{col1}/{col2}'].iloc[0]*(px**2))))\n",
    "            print(f\"Column ID: {col1}\" ,\"r1 = \", (df[f'r1-{col1}/{col2}'].iloc[0])*1e9, \"nm\", \"r2 = \", (df[f'r2-{col1}/{col2}'].iloc[0])*1e9, \"nm\", \"r3 = \", (df[f'r3-{col1}/{col2}'].iloc[0])*1e9, \"nm\")\n",
    "            print(f\"ratio for {col1} =\", df[f'ratio10/5{col1}/{col2}'].iloc[0], \"ratio2 for {col1} =\", df[f'ratio15/10{col1}/{col2}'].iloc[0])\n",
    "\n",
    "            # Calculate the radius - average of the three values\n",
    "            r = (df[f'r1-{col1}/{col2}'].iloc[0] + df[f'r2-{col1}/{col2}'].iloc[0] + df[f'r3-{col1}/{col2}'].iloc[0])/3 * 1e9\n",
    "\n",
    "            # Create a new dataframe to store the results\n",
    "            results_df = pd.concat([results_df, pd.DataFrame({'ID': [col1], 'r': [r], 'ratio10/5': [df[f'ratio10/5{col1}/{col2}'].iloc[0]], 'ratio15/10': [df[f'ratio15/10{col1}/{col2}'].iloc[0]] })])\n",
    "\n",
    "    progress_bar.update(1)\n",
    "progress_bar.close()\n",
    "\n",
    "\n",
    "# Display the contents of the CSV file\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roots of the polynomial are: [56.17942051+1.86965308j 56.17942051-1.86965308j 26.65839128+0.j        ]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a0 = -70.74803\n",
    "a1 = 5.169734\n",
    "a2 = -0.1167653\n",
    "a3 = 0.000839934\n",
    "# Define the polynomial coefficients\n",
    "coefficients = [a3, a2, a1, a0]\n",
    "\n",
    "# Find the roots of the polynomial\n",
    "roots = np.roots(coefficients)\n",
    "\n",
    "# Display the roots\n",
    "print(\"The roots of the polynomial are:\", roots)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment 1 saved.\n",
      "Segment 2 saved.\n",
      "Segment 3 saved.\n",
      "Segment 4 saved.\n",
      "Segment 5 saved.\n",
      "Segment 6 saved.\n",
      "Segment 7 saved.\n",
      "Segment 8 saved.\n",
      "Segment 9 saved.\n",
      "Segment 10 saved.\n",
      "Segment 11 saved.\n",
      "Segment 12 saved.\n",
      "Segment 13 saved.\n",
      "Segment 14 saved.\n",
      "Segment 15 saved.\n",
      "Segment 16 saved.\n",
      "Segment 17 saved.\n",
      "Segment 18 saved.\n",
      "Segment 19 saved.\n",
      "Segment 20 saved.\n",
      "Segment 21 saved.\n",
      "Segment 22 saved.\n",
      "Segment 23 saved.\n",
      "Segment 24 saved.\n",
      "Segment 25 saved.\n",
      "Segment 26 saved.\n",
      "Segment 27 saved.\n",
      "Segment 28 saved.\n",
      "Segment 29 saved.\n",
      "Segment 30 saved.\n",
      "Segment 31 saved.\n",
      "Segment 32 saved.\n",
      "Segment 33 saved.\n",
      "Segment 34 saved.\n",
      "Segment 35 saved.\n",
      "Segment 36 saved.\n",
      "Segment 37 saved.\n",
      "Segment 38 saved.\n",
      "Segment 39 saved.\n",
      "Segment 40 saved.\n",
      "Segment 41 saved.\n",
      "Segment 42 saved.\n",
      "Segment 43 saved.\n",
      "Segment 44 saved.\n",
      "Segment 45 saved.\n",
      "Segment 46 saved.\n",
      "Segment 47 saved.\n",
      "Segment 48 saved.\n",
      "Segment 49 saved.\n",
      "Segment 50 saved.\n",
      "Segment 51 saved.\n",
      "Segment 52 saved.\n",
      "Segment 53 saved.\n",
      "Segment 54 saved.\n",
      "Segment 55 saved.\n",
      "Segment 56 saved.\n",
      "Segment 57 saved.\n",
      "Segment 58 saved.\n",
      "Segment 59 saved.\n",
      "Segment 60 saved.\n",
      "Segment 61 saved.\n",
      "Segment 62 saved.\n",
      "Segment 63 saved.\n",
      "Segment 64 saved.\n",
      "Segment 65 saved.\n",
      "Segment 66 saved.\n",
      "Segment 67 saved.\n",
      "Segment 68 saved.\n",
      "Segment 69 saved.\n",
      "Segment 70 saved.\n",
      "Segment 71 saved.\n",
      "Segment 72 saved.\n",
      "Segment 73 saved.\n",
      "Segment 74 saved.\n",
      "Segment 75 saved.\n",
      "Segment 76 saved.\n",
      "Segment 77 saved.\n",
      "Segment 78 saved.\n",
      "Segment 79 saved.\n"
     ]
    }
   ],
   "source": [
    "# Define the output directory for the split videos\n",
    "\n",
    "video_path = r'_raw\\_vids\\600\\0101_v1.mpg'\n",
    "output_dir = 'splits\\\\600'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize the frame counter\n",
    "frame_counter = 0\n",
    "segment_counter = 0\n",
    "\n",
    "# Reopen the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video file opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "# Get the width and height of the video\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Loop through the video frames\n",
    "while True:\n",
    "    frames = []\n",
    "    for _ in range(60):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "        frame_counter += 1\n",
    "\n",
    "    if not frames:\n",
    "        break\n",
    "\n",
    "    # Define the codec and create VideoWriter object to save the segment\n",
    "    segment_path = os.path.join(output_dir, f'segment_{segment_counter}.mp4')\n",
    "    out = cv2.VideoWriter(segment_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    # Write the frames to the segment video\n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "\n",
    "    # Release the VideoWriter object\n",
    "    out.release()\n",
    "\n",
    "    # Increment the segment counter\n",
    "    segment_counter += 1\n",
    "    print(f\"Segment {segment_counter} saved.\")\n",
    "\n",
    "\n",
    "    # Set the video position back by 30 frames for overlapping\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_counter - 30)\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hex format is correct!\n"
     ]
    }
   ],
   "source": [
    "import binascii\n",
    "\n",
    "salt = \"a7682b1ae5783053d9\"\n",
    "hash_value = \"7fbdca4cf62192e6df921629bef4855b1dbf9f8be5d57ff65a67763f1c9197ef\"\n",
    "\n",
    "try:\n",
    "    binascii.unhexlify(salt)  # Check if valid hex\n",
    "    binascii.unhexlify(hash_value)  # Check if valid hex\n",
    "    print(\"Hex format is correct!\")\n",
    "except binascii.Error:\n",
    "    print(\"Invalid hex format! Check your values.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
